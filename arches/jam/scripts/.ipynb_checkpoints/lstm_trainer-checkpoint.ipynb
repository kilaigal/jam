{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Generation V1\n",
    "\n",
    "\n",
    "This script builds a model to learn music sequences from MIDI files. The model is a stacked LSTM model which takes as input a set of temporal notes and predicts the next note in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libs for music processing \n",
    "import msgpack\n",
    "import mido\n",
    "from mido import MidiFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using music 21\n",
    "\n",
    "from music21 import midi\n",
    "from music21 import converter, instrument, note, chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# For preprocessing and modeling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching data from midi files\n",
    "\n",
    "They are extracted as notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../arches/data/kalyani.mid'\n",
    "e = None\n",
    "def get_notes():\n",
    "    global e\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    for file in glob.glob(\"../arches/data/kalyani.mid\"):\n",
    "        mf = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = None\n",
    "\n",
    "        try: # file has instrument parts\n",
    "            s2 = instrument.partitionByInstrument(mf)\n",
    "            print(s2.parts)\n",
    "            notes_to_parse = s2.parts[0].recurse() \n",
    "        except: # file has notes in a flat structure\n",
    "            notes_to_parse = mf.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            e = element\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.nameWithOctave))\n",
    "                # print(element.nameWithOctave)\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                # print(\"Parsing a chord\")\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ../arches/data/kalyani.mid\n",
      "<music21.stream.iterator.StreamIterator for Score:0x10e8f9e80 @:0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes = get_notes()\n",
    "len(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing \n",
    "\n",
    "Read the data as a sequence in to seq out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input stream shape (67, 10, 1)\n",
      "Output stream shape (67, 20)\n"
     ]
    }
   ],
   "source": [
    "# Encode the notes in file\n",
    "unique_notes = sorted(set(notes))\n",
    "vocab_size = len(unique_notes)\n",
    "\n",
    "# generate forward encoding\n",
    "noteName_encoding = dict(\n",
    "    (noteName, num) for num, noteName in enumerate(unique_notes)) \n",
    "\n",
    "# generate reverse encoding\n",
    "encoding_to_note = dict(\n",
    "    (number, note) for number, note in enumerate(unique_notes))\n",
    "\n",
    "\n",
    "# Set training params\n",
    "input_sequence_length = 10\n",
    "x__inputs = []\n",
    "y__outputs = []\n",
    "\n",
    "# read the note stream and append to training data\n",
    "for i in range(len(notes) - input_sequence_length):\n",
    "    tmp_input = notes[i: i+input_sequence_length]\n",
    "    tmp_output = notes[i+ input_sequence_length]\n",
    "    x__inputs.append(list([noteName_encoding[ip] for ip in tmp_input]))\n",
    "    y__outputs.append(noteName_encoding[tmp_output])\n",
    "\n",
    "# Reshape the data since LSTMs want a 3-D input and a 1-D output\n",
    "x__inputs = np.reshape(x__inputs, (len(x__inputs), input_sequence_length, 1))\n",
    "\n",
    "# Normalize the data \n",
    "x__inputs = x__inputs/float(vocab_size-1)\n",
    "y__outputs = np_utils.to_categorical(y__outputs)\n",
    "print(\"Input stream shape %s\" %str(np.array(x__inputs).shape))\n",
    "print(\"Output stream shape %s\" %str(np.array(y__outputs).shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('A4', 0), ('A5', 1), ('B-4', 2), ('B3', 3), ('B4', 4), ('C#5', 5), ('C5', 6), ('D4', 7), ('D5', 8), ('E-4', 9), ('E-5', 10), ('E4', 11), ('E5', 12), ('F#4', 13), ('F#5', 14), ('F5', 15), ('G#4', 16), ('G#5', 17), ('G4', 18), ('G5', 19)])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check the data transform\n",
    "assert(np.min(x__inputs) == 0)\n",
    "assert(np.max(x__inputs) == 1)\n",
    "assert(vocab_size == y__outputs.shape[1])\n",
    "noteName_encoding.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libs for m1odeling \n",
    "from keras.layers import LSTM, Dropout, Dense, Activation\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(30, \n",
    "               input_shape = (input_sequence_length, 1),\n",
    "               return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(30, return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(30))\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 2.6013\n",
      "Epoch 2/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5827\n",
      "Epoch 3/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5785\n",
      "Epoch 4/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5833\n",
      "Epoch 5/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5748\n",
      "Epoch 6/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5841\n",
      "Epoch 7/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5740\n",
      "Epoch 8/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5861\n",
      "Epoch 9/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5645\n",
      "Epoch 10/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5828\n",
      "Epoch 11/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5580\n",
      "Epoch 12/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5515\n",
      "Epoch 13/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5522\n",
      "Epoch 14/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5558\n",
      "Epoch 15/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5418\n",
      "Epoch 16/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5385\n",
      "Epoch 17/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5125\n",
      "Epoch 18/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5174\n",
      "Epoch 19/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5127\n",
      "Epoch 20/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5122\n",
      "Epoch 21/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5130\n",
      "Epoch 22/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5204\n",
      "Epoch 23/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 2.4828\n",
      "Epoch 24/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5184\n",
      "Epoch 25/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5078\n",
      "Epoch 26/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5199\n",
      "Epoch 27/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.4833\n",
      "Epoch 28/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.4532\n",
      "Epoch 29/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.4571\n",
      "Epoch 30/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.4564\n",
      "Epoch 31/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.4533\n",
      "Epoch 32/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.4625\n",
      "Epoch 33/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.4687\n",
      "Epoch 34/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 2.4108\n",
      "Epoch 35/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 2.4756\n",
      "Epoch 36/300\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 2.4228\n",
      "Epoch 37/300\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 2.4557\n",
      "Epoch 38/300\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 2.4526\n",
      "Epoch 39/300\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 2.4308\n",
      "Epoch 40/300\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 2.3618\n",
      "Epoch 41/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.4190\n",
      "Epoch 42/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.4210\n",
      "Epoch 43/300\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 2.4084\n",
      "Epoch 44/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 2.4119\n",
      "Epoch 45/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.3780\n",
      "Epoch 46/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 2.3726\n",
      "Epoch 47/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 2.3666\n",
      "Epoch 48/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.3412\n",
      "Epoch 49/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 2.3684\n",
      "Epoch 50/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 2.3485\n",
      "Epoch 51/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.3826\n",
      "Epoch 52/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 2.3116\n",
      "Epoch 53/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 2.3191\n",
      "Epoch 54/300\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 2.3003\n",
      "Epoch 55/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 2.3345\n",
      "Epoch 56/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 2.3435\n",
      "Epoch 57/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.2954\n",
      "Epoch 58/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.2690\n",
      "Epoch 59/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 2.3047\n",
      "Epoch 60/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 2.2583\n",
      "Epoch 61/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 2.3221\n",
      "Epoch 62/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 2.3309\n",
      "Epoch 63/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.2103\n",
      "Epoch 64/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.2563\n",
      "Epoch 65/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.2263\n",
      "Epoch 66/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.2700\n",
      "Epoch 67/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.2960\n",
      "Epoch 68/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.2134\n",
      "Epoch 69/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.2927\n",
      "Epoch 70/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.2269\n",
      "Epoch 71/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.2524\n",
      "Epoch 72/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1961\n",
      "Epoch 73/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1889\n",
      "Epoch 74/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.2155\n",
      "Epoch 75/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.2214\n",
      "Epoch 76/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1664\n",
      "Epoch 77/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1473\n",
      "Epoch 78/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1737\n",
      "Epoch 79/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1251\n",
      "Epoch 80/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1312\n",
      "Epoch 81/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.2142\n",
      "Epoch 82/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1202\n",
      "Epoch 83/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1058\n",
      "Epoch 84/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.0854\n",
      "Epoch 85/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1361\n",
      "Epoch 86/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1228\n",
      "Epoch 87/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1296\n",
      "Epoch 88/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.0883\n",
      "Epoch 89/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1224\n",
      "Epoch 90/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1474\n",
      "Epoch 91/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1401\n",
      "Epoch 92/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1729\n",
      "Epoch 93/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.1617\n",
      "Epoch 94/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.0393\n",
      "Epoch 95/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.0272\n",
      "Epoch 96/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.0701\n",
      "Epoch 97/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 2.1099\n",
      "Epoch 98/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.0767\n",
      "Epoch 99/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.0729\n",
      "Epoch 100/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.0502\n",
      "Epoch 101/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.0157\n",
      "Epoch 102/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 4ms/step - loss: 2.0653\n",
      "Epoch 103/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.0304\n",
      "Epoch 104/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.0246\n",
      "Epoch 105/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.0026\n",
      "Epoch 106/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.0519\n",
      "Epoch 107/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9879\n",
      "Epoch 108/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.0430\n",
      "Epoch 109/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9549\n",
      "Epoch 110/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9624\n",
      "Epoch 111/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9581\n",
      "Epoch 112/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9695\n",
      "Epoch 113/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9781\n",
      "Epoch 114/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9700\n",
      "Epoch 115/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9203\n",
      "Epoch 116/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9485\n",
      "Epoch 117/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 2.0020\n",
      "Epoch 118/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9738\n",
      "Epoch 119/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9508\n",
      "Epoch 120/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.0090\n",
      "Epoch 121/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9960\n",
      "Epoch 122/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9459\n",
      "Epoch 123/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9052\n",
      "Epoch 124/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9219\n",
      "Epoch 125/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9144\n",
      "Epoch 126/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.8811\n",
      "Epoch 127/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.8733\n",
      "Epoch 128/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9355\n",
      "Epoch 129/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.8766\n",
      "Epoch 130/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.8782\n",
      "Epoch 131/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.9025\n",
      "Epoch 132/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 2.0047\n",
      "Epoch 133/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.8079\n",
      "Epoch 134/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.8441\n",
      "Epoch 135/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.8675\n",
      "Epoch 136/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.7945\n",
      "Epoch 137/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7683\n",
      "Epoch 138/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.8723\n",
      "Epoch 139/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.8266\n",
      "Epoch 140/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.8028A: 0s - loss: 1.843\n",
      "Epoch 141/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.7568\n",
      "Epoch 142/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.8197\n",
      "Epoch 143/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.7860\n",
      "Epoch 144/300\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 1.8768\n",
      "Epoch 145/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.8238\n",
      "Epoch 146/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.7440\n",
      "Epoch 147/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.8710\n",
      "Epoch 148/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7640\n",
      "Epoch 149/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7933\n",
      "Epoch 150/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7408\n",
      "Epoch 151/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7402\n",
      "Epoch 152/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7091\n",
      "Epoch 153/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7347\n",
      "Epoch 154/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.8038\n",
      "Epoch 155/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7641\n",
      "Epoch 156/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7065\n",
      "Epoch 157/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.8411\n",
      "Epoch 158/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7107\n",
      "Epoch 159/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7149\n",
      "Epoch 160/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7490\n",
      "Epoch 161/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7687\n",
      "Epoch 162/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7057\n",
      "Epoch 163/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6875\n",
      "Epoch 164/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7270\n",
      "Epoch 165/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6902\n",
      "Epoch 166/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6658\n",
      "Epoch 167/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.8132\n",
      "Epoch 168/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7090\n",
      "Epoch 169/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6722\n",
      "Epoch 170/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7307\n",
      "Epoch 171/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6698\n",
      "Epoch 172/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6274\n",
      "Epoch 173/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7501\n",
      "Epoch 174/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7217\n",
      "Epoch 175/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6379\n",
      "Epoch 176/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6305\n",
      "Epoch 177/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7037\n",
      "Epoch 178/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7054\n",
      "Epoch 179/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7038\n",
      "Epoch 180/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.7055\n",
      "Epoch 181/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5892\n",
      "Epoch 182/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6135\n",
      "Epoch 183/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6590\n",
      "Epoch 184/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5810\n",
      "Epoch 185/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6075\n",
      "Epoch 186/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.8152\n",
      "Epoch 187/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5962\n",
      "Epoch 188/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6754\n",
      "Epoch 189/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6098\n",
      "Epoch 190/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6072\n",
      "Epoch 191/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5227\n",
      "Epoch 192/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6966\n",
      "Epoch 193/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5015\n",
      "Epoch 194/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6823\n",
      "Epoch 195/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6144\n",
      "Epoch 196/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5724\n",
      "Epoch 197/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5976\n",
      "Epoch 198/300\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 1.5429\n",
      "Epoch 199/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5568\n",
      "Epoch 200/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5568\n",
      "Epoch 201/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6349\n",
      "Epoch 202/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5578\n",
      "Epoch 203/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6390\n",
      "Epoch 204/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5065\n",
      "Epoch 205/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5957\n",
      "Epoch 206/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6123\n",
      "Epoch 207/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5417\n",
      "Epoch 208/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5677\n",
      "Epoch 209/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5395\n",
      "Epoch 210/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.5194\n",
      "Epoch 211/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.5617\n",
      "Epoch 212/300\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 1.4844\n",
      "Epoch 213/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.4542\n",
      "Epoch 214/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5274\n",
      "Epoch 215/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5166\n",
      "Epoch 216/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.5016\n",
      "Epoch 217/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.5796\n",
      "Epoch 218/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5117\n",
      "Epoch 219/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.4894\n",
      "Epoch 220/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.4519\n",
      "Epoch 221/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.4600\n",
      "Epoch 222/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.5254\n",
      "Epoch 223/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.4777\n",
      "Epoch 224/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.4426\n",
      "Epoch 225/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.5147\n",
      "Epoch 226/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.4150\n",
      "Epoch 227/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.5334\n",
      "Epoch 228/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.4677\n",
      "Epoch 229/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.4430\n",
      "Epoch 230/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.4189\n",
      "Epoch 231/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.4979\n",
      "Epoch 232/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.4879\n",
      "Epoch 233/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.5208\n",
      "Epoch 234/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.4120\n",
      "Epoch 235/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.4415\n",
      "Epoch 236/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.3852\n",
      "Epoch 237/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.4218\n",
      "Epoch 238/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.4410\n",
      "Epoch 239/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3890\n",
      "Epoch 240/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.4837\n",
      "Epoch 241/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.4682\n",
      "Epoch 242/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3087\n",
      "Epoch 243/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3861\n",
      "Epoch 244/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3499\n",
      "Epoch 245/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3152\n",
      "Epoch 246/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.4031\n",
      "Epoch 247/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.4092\n",
      "Epoch 248/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3458\n",
      "Epoch 249/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.4143\n",
      "Epoch 250/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.4246\n",
      "Epoch 251/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3208\n",
      "Epoch 252/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.3905\n",
      "Epoch 253/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.2997\n",
      "Epoch 254/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.3494\n",
      "Epoch 255/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.3377\n",
      "Epoch 256/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.3877\n",
      "Epoch 257/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.3437\n",
      "Epoch 258/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3806\n",
      "Epoch 259/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.4324\n",
      "Epoch 260/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.3150\n",
      "Epoch 261/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.3110\n",
      "Epoch 262/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.3974\n",
      "Epoch 263/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.3124\n",
      "Epoch 264/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3748\n",
      "Epoch 265/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.2915\n",
      "Epoch 266/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3778\n",
      "Epoch 267/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3157\n",
      "Epoch 268/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.3330\n",
      "Epoch 269/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3859\n",
      "Epoch 270/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.3349\n",
      "Epoch 271/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3051\n",
      "Epoch 272/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3410\n",
      "Epoch 273/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.2712\n",
      "Epoch 274/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.2708\n",
      "Epoch 275/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.2835\n",
      "Epoch 276/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3604\n",
      "Epoch 277/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.2115\n",
      "Epoch 278/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.2721\n",
      "Epoch 279/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.2351\n",
      "Epoch 280/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.2538\n",
      "Epoch 281/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.1843\n",
      "Epoch 282/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.4322\n",
      "Epoch 283/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.2846\n",
      "Epoch 284/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.2839\n",
      "Epoch 285/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.2689\n",
      "Epoch 286/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.2695\n",
      "Epoch 287/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.2889\n",
      "Epoch 288/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.2430\n",
      "Epoch 289/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.2615\n",
      "Epoch 290/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.2883\n",
      "Epoch 291/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.1656\n",
      "Epoch 292/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.2831\n",
      "Epoch 293/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.1835\n",
      "Epoch 294/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.3214\n",
      "Epoch 295/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.1874\n",
      "Epoch 296/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.1722\n",
      "Epoch 297/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.1856\n",
      "Epoch 298/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.1426\n",
      "Epoch 299/300\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1.2641\n",
      "Epoch 300/300\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.2297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1449932e8>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x__inputs, y__outputs\n",
    "          , epochs=300\n",
    "          , batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed note sequence\n",
    "debug=False\n",
    "start = 0\n",
    "pattern = notes[start: start+input_sequence_length]\n",
    "ouput_notes = []\n",
    "for i in range(10):\n",
    "    # Encode and transform the note sequence\n",
    "    encoded_note = [noteName_encoding[pattern_note] for pattern_note in pattern]\n",
    "    transformed_note = np.array(encoded_note)/float(vocab_size-1)\n",
    "    transformed_note = np.reshape(transformed_note, (1, input_sequence_length, 1))\n",
    "    \n",
    "    # Score the model\n",
    "    preds = model.predict_classes(transformed_note)\n",
    "    pred_note = encoding_to_note[preds[0]]\n",
    "    ouput_notes.append(pred_note)\n",
    "    if(debug):\n",
    "        print('Iter %d | notes %s' %(i, pattern))\n",
    "        print('pred_note is %s' %pred_note)\n",
    "    \n",
    "    # Update the scoring input pattern\n",
    "    pattern.append(pred_note)\n",
    "    pattern = pattern[-input_sequence_length: len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted notes ['E4', 'D4', 'B3', 'D4', 'D5', 'E-4', 'G#4', 'C#5', 'C#5', 'E5']\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted notes %s\"%(ouput_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the music!\n",
    "predicted_notes = []\n",
    "offset = 0\n",
    "\n",
    "for prediction_output in prediction_outputs:\n",
    "    n = note.Note(prediction_output)\n",
    "    n.offset = offset\n",
    "    n.storedInstrument = instrument.Piano()\n",
    "    predicted_notes.append(n)\n",
    "    offset += 0.5\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
